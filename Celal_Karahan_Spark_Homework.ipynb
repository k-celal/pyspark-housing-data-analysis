{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gMeOeP65DQL0"
   },
   "source": [
    "# Gerekli kütüphanelerin ve JDK kurulması\n",
    "Gerekli Python kütüphanelerinin ve JDK'nın (Java Development Kit) kurulumunu gerçekleştiriyoruz. JDK, Apache Spark'ın çalışması için gereklidir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uGbqb8rcZgTL",
    "outputId": "77bb0f97-7944-4d02-ed7d-c453918e6688"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "0% [Working]\r",
      "            \r",
      "Hit:1 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
      "\r",
      "0% [Waiting for headers] [Waiting for headers] [Waiting for headers] [Connecting to ppa.launchpadcon\r",
      "                                                                                                    \r",
      "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
      "\r",
      "                                                                                                    \r",
      "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
      "\r",
      "                                                                                                    \r",
      "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
      "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
      "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
      "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
      "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
      "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
      "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
      "Get:11 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,920 kB]\n",
      "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,357 kB]\n",
      "Fetched 3,510 kB in 3s (1,387 kB/s)\n",
      "Reading package lists... Done\n"
     ]
    }
   ],
   "source": [
    "!apt-get update\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
    "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iWUdqEj6jr-D",
    "outputId": "4c7e8dec-432d-4194-bcfe-e087563350dd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Downloading pyspark-3.5.1.tar.gz (317.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.0/317.0 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
      "Building wheels for collected packages: pyspark\n",
      "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for pyspark: filename=pyspark-3.5.1-py2.py3-none-any.whl size=317488491 sha256=bd87d11135cb492e2be23849e4920e14d03abbe4b1a4f70aacd476bb04a7d8b3\n",
      "  Stored in directory: /root/.cache/pip/wheels/80/1d/60/2c256ed38dddce2fdd93be545214a63e02fbd8d74fb0b7f3a6\n",
      "Successfully built pyspark\n",
      "Installing collected packages: pyspark\n",
      "Successfully installed pyspark-3.5.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JHi0HY1rDoXD"
   },
   "source": [
    "# Ortam değişkenleriin ayarlanması\n",
    "Java ve Spark'ın Python ortamında doğru bir şekilde bulunması için gereken ortam değişkenlerini ayarlanması."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "9Fqe45eIa6tA"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wJ8LWqPSEHp2"
   },
   "source": [
    "# Sparkın başlatılması\n",
    "Bu kod parçaları, Spark oturumunu başlatır. findspark kütüphanesi, Spark'ı Python ortamında bulmayı ve etkinleştirmeyi sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "NMScjeZkbXeb"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 222
    },
    "id": "2tGLKEqZkC94",
    "outputId": "deab98d4-a87a-40c6-b707-6f746b596620"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://61ae3243a5d2:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7ec7e0067a60>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRKtKzAqE69W"
   },
   "source": [
    "# Google Drive'ı bağlama\n",
    "Google drive a bağlanmak için gerekli kod parçaları"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WsvpqLs_kuTS",
    "outputId": "8708496d-2ff9-4c4e-e7b6-9e09aa45a5d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive,files\n",
    "import os\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "workspace_path = \"/content/drive/MyDrive/SparkOdev/\"\n",
    "\n",
    "os.chdir(workspace_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CLF5WLyNFI6M"
   },
   "source": [
    "# Veri Okuma\n",
    "Veriyi belirtile yoldan okuyup df isimli Spark DataFrame e atanır (Drive içerisine SparkOdev klasörü açınız ve içerisine veri setini yükleyiniz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "0kipGQj8bccS"
   },
   "outputs": [],
   "source": [
    "df = spark.read.csv(workspace_path+'housing.csv',inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jt6BFNPCkbEH",
    "outputId": "5885757f-4fac-4a96-f965-2e692c30241d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|\n",
      "|  -122.22|   37.86|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|       8.3014|          358500.0|       NEAR BAY|\n",
      "|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|\n",
      "|  -122.25|   37.85|              52.0|     1274.0|         235.0|     558.0|     219.0|       5.6431|          341300.0|       NEAR BAY|\n",
      "|  -122.25|   37.85|              52.0|     1627.0|         280.0|     565.0|     259.0|       3.8462|          342200.0|       NEAR BAY|\n",
      "|  -122.25|   37.85|              52.0|      919.0|         213.0|     413.0|     193.0|       4.0368|          269700.0|       NEAR BAY|\n",
      "|  -122.25|   37.84|              52.0|     2535.0|         489.0|    1094.0|     514.0|       3.6591|          299200.0|       NEAR BAY|\n",
      "|  -122.25|   37.84|              52.0|     3104.0|         687.0|    1157.0|     647.0|         3.12|          241400.0|       NEAR BAY|\n",
      "|  -122.26|   37.84|              42.0|     2555.0|         665.0|    1206.0|     595.0|       2.0804|          226700.0|       NEAR BAY|\n",
      "|  -122.25|   37.84|              52.0|     3549.0|         707.0|    1551.0|     714.0|       3.6912|          261100.0|       NEAR BAY|\n",
      "|  -122.26|   37.85|              52.0|     2202.0|         434.0|     910.0|     402.0|       3.2031|          281500.0|       NEAR BAY|\n",
      "|  -122.26|   37.85|              52.0|     3503.0|         752.0|    1504.0|     734.0|       3.2705|          241800.0|       NEAR BAY|\n",
      "|  -122.26|   37.85|              52.0|     2491.0|         474.0|    1098.0|     468.0|        3.075|          213500.0|       NEAR BAY|\n",
      "|  -122.26|   37.84|              52.0|      696.0|         191.0|     345.0|     174.0|       2.6736|          191300.0|       NEAR BAY|\n",
      "|  -122.26|   37.85|              52.0|     2643.0|         626.0|    1212.0|     620.0|       1.9167|          159200.0|       NEAR BAY|\n",
      "|  -122.26|   37.85|              50.0|     1120.0|         283.0|     697.0|     264.0|        2.125|          140000.0|       NEAR BAY|\n",
      "|  -122.27|   37.85|              52.0|     1966.0|         347.0|     793.0|     331.0|        2.775|          152500.0|       NEAR BAY|\n",
      "|  -122.27|   37.85|              52.0|     1228.0|         293.0|     648.0|     303.0|       2.1202|          155500.0|       NEAR BAY|\n",
      "|  -122.26|   37.84|              50.0|     2239.0|         455.0|     990.0|     419.0|       1.9911|          158700.0|       NEAR BAY|\n",
      "|  -122.27|   37.84|              52.0|     1503.0|         298.0|     690.0|     275.0|       2.6033|          162900.0|       NEAR BAY|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MTGxcxgobuMv",
    "outputId": "c00c2f83-1462-4feb-9220-68cd4ad6ef13"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+---------------+\n",
      "|summary|          longitude|         latitude|housing_median_age|       total_rooms|    total_bedrooms|        population|       households|     median_income|median_house_value|ocean_proximity|\n",
      "+-------+-------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+---------------+\n",
      "|  count|              20640|            20640|             20640|             20640|             20433|             20640|            20640|             20640|             20640|          20640|\n",
      "|   mean|-119.56970445736148| 35.6318614341087|28.639486434108527|2635.7630813953488| 537.8705525375618|1425.4767441860465|499.5396802325581|3.8706710029070246|206855.81690891474|           null|\n",
      "| stddev|  2.003531723502584|2.135952397457101| 12.58555761211163|2181.6152515827944|421.38507007403115|  1132.46212176534|382.3297528316098| 1.899821717945263|115395.61587441359|           null|\n",
      "|    min|            -124.35|            32.54|               1.0|               2.0|               1.0|               3.0|              1.0|            0.4999|           14999.0|      <1H OCEAN|\n",
      "|    max|            -114.31|            41.95|              52.0|           39320.0|            6445.0|           35682.0|           6082.0|           15.0001|          500001.0|     NEAR OCEAN|\n",
      "+-------+-------------------+-----------------+------------------+------------------+------------------+------------------+-----------------+------------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VnLR0pcLgYz"
   },
   "source": [
    "# Null Değerlerin Bulunması\n",
    "Bu kod parçası, her sütunda bulunan null değerlerin sayısını hesaplar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3EkG5AfLYRg",
    "outputId": "84edd269-2d55-446c-ce27-d5ec58bcbfa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|        0|       0|                 0|          0|           207|         0|         0|            0|                 0|              0|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "null_counts = df.select([sum(col(column).isNull().cast(\"int\")).alias(column) for column in df.columns])\n",
    "\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXxbojXoLz8Z"
   },
   "source": [
    "# Null Değerlerin Silinmesi\n",
    "DataFrame'deki herhangi bir satırda null değer bulunan satırları siler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "QiFBZK3wxKWm"
   },
   "outputs": [],
   "source": [
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FsdtOhieoWHm",
    "outputId": "09de60ca-5f4a-46b8-c0cb-fff9a3a91c48"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|        0|       0|                 0|          0|             0|         0|         0|            0|                 0|              0|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "null_counts = df.select([sum(col(column).isNull().cast(\"int\")).alias(column) for column in df.columns])\n",
    "\n",
    "null_counts.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CGJQGXXbL-DV"
   },
   "source": [
    "# Null Değerlerin Ortalama Değer ile Doldurulması\n",
    "'total_bedrooms' sütunundaki null değerleri hesaplanan ortalama değer ile doldurur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z_GZCY8JpZSe",
    "outputId": "a10a8869-8392-441b-97ec-6ad2358618aa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|       NEAR BAY|\n",
      "|  -122.22|   37.86|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|       8.3014|          358500.0|       NEAR BAY|\n",
      "|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|       NEAR BAY|\n",
      "|  -122.25|   37.85|              52.0|     1274.0|         235.0|     558.0|     219.0|       5.6431|          341300.0|       NEAR BAY|\n",
      "|  -122.25|   37.85|              52.0|     1627.0|         280.0|     565.0|     259.0|       3.8462|          342200.0|       NEAR BAY|\n",
      "|  -122.25|   37.85|              52.0|      919.0|         213.0|     413.0|     193.0|       4.0368|          269700.0|       NEAR BAY|\n",
      "|  -122.25|   37.84|              52.0|     2535.0|         489.0|    1094.0|     514.0|       3.6591|          299200.0|       NEAR BAY|\n",
      "|  -122.25|   37.84|              52.0|     3104.0|         687.0|    1157.0|     647.0|         3.12|          241400.0|       NEAR BAY|\n",
      "|  -122.26|   37.84|              42.0|     2555.0|         665.0|    1206.0|     595.0|       2.0804|          226700.0|       NEAR BAY|\n",
      "|  -122.25|   37.84|              52.0|     3549.0|         707.0|    1551.0|     714.0|       3.6912|          261100.0|       NEAR BAY|\n",
      "|  -122.26|   37.85|              52.0|     2202.0|         434.0|     910.0|     402.0|       3.2031|          281500.0|       NEAR BAY|\n",
      "|  -122.26|   37.85|              52.0|     3503.0|         752.0|    1504.0|     734.0|       3.2705|          241800.0|       NEAR BAY|\n",
      "|  -122.26|   37.85|              52.0|     2491.0|         474.0|    1098.0|     468.0|        3.075|          213500.0|       NEAR BAY|\n",
      "|  -122.26|   37.84|              52.0|      696.0|         191.0|     345.0|     174.0|       2.6736|          191300.0|       NEAR BAY|\n",
      "|  -122.26|   37.85|              52.0|     2643.0|         626.0|    1212.0|     620.0|       1.9167|          159200.0|       NEAR BAY|\n",
      "|  -122.26|   37.85|              50.0|     1120.0|         283.0|     697.0|     264.0|        2.125|          140000.0|       NEAR BAY|\n",
      "|  -122.27|   37.85|              52.0|     1966.0|         347.0|     793.0|     331.0|        2.775|          152500.0|       NEAR BAY|\n",
      "|  -122.27|   37.85|              52.0|     1228.0|         293.0|     648.0|     303.0|       2.1202|          155500.0|       NEAR BAY|\n",
      "|  -122.26|   37.84|              50.0|     2239.0|         455.0|     990.0|     419.0|       1.9911|          158700.0|       NEAR BAY|\n",
      "|  -122.27|   37.84|              52.0|     1503.0|         298.0|     690.0|     275.0|       2.6033|          162900.0|       NEAR BAY|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean\n",
    "\n",
    "mean_value = df.select(mean(df[\"total_bedrooms\"])).collect()[0][0]\n",
    "\n",
    "df_filled = df.na.fill(mean_value, [\"total_bedrooms\"])\n",
    "\n",
    "df_filled.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KKaX8BctqWnz"
   },
   "outputs": [],
   "source": [
    "df=df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_KItb-d_qMf7",
    "outputId": "8e58e7b7-30a0-4404-d453-17e4a1c94e65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|        0|       0|                 0|          0|             0|         0|         0|            0|                 0|              0|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "null_counts = df.select([sum(col(column).isNull().cast(\"int\")).alias(column) for column in df.columns])\n",
    "\n",
    "null_counts.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qxjfEK6uMMyJ"
   },
   "source": [
    "# Kategorik değişkenin incelenmesi\n",
    " 'ocean_proximity' sütunundaki benzersiz değerleri bulur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "luc-PhN5qQ39",
    "outputId": "32a45c9c-3c85-4c31-d871-79e46b35ff1f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+\n",
      "|ocean_proximity|\n",
      "+---------------+\n",
      "|         ISLAND|\n",
      "|     NEAR OCEAN|\n",
      "|       NEAR BAY|\n",
      "|      <1H OCEAN|\n",
      "|         INLAND|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "unique_values = df.select(\"ocean_proximity\").distinct()\n",
    "\n",
    "unique_values.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qbAPFQMDMcfb"
   },
   "source": [
    "# Kategorik Değerlerin Dönüştürülmesi\n",
    "Kategorik değişkenlerin öncelikle OrdinalEncoding yapılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bqgbWUF8q0oR",
    "outputId": "9232ebdf-2903-4c7b-ba6f-def5f65f9af1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|            3.0|\n",
      "|  -122.22|   37.86|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|       8.3014|          358500.0|            3.0|\n",
      "|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|            3.0|\n",
      "|  -122.25|   37.85|              52.0|     1274.0|         235.0|     558.0|     219.0|       5.6431|          341300.0|            3.0|\n",
      "|  -122.25|   37.85|              52.0|     1627.0|         280.0|     565.0|     259.0|       3.8462|          342200.0|            3.0|\n",
      "|  -122.25|   37.85|              52.0|      919.0|         213.0|     413.0|     193.0|       4.0368|          269700.0|            3.0|\n",
      "|  -122.25|   37.84|              52.0|     2535.0|         489.0|    1094.0|     514.0|       3.6591|          299200.0|            3.0|\n",
      "|  -122.25|   37.84|              52.0|     3104.0|         687.0|    1157.0|     647.0|         3.12|          241400.0|            3.0|\n",
      "|  -122.26|   37.84|              42.0|     2555.0|         665.0|    1206.0|     595.0|       2.0804|          226700.0|            3.0|\n",
      "|  -122.25|   37.84|              52.0|     3549.0|         707.0|    1551.0|     714.0|       3.6912|          261100.0|            3.0|\n",
      "|  -122.26|   37.85|              52.0|     2202.0|         434.0|     910.0|     402.0|       3.2031|          281500.0|            3.0|\n",
      "|  -122.26|   37.85|              52.0|     3503.0|         752.0|    1504.0|     734.0|       3.2705|          241800.0|            3.0|\n",
      "|  -122.26|   37.85|              52.0|     2491.0|         474.0|    1098.0|     468.0|        3.075|          213500.0|            3.0|\n",
      "|  -122.26|   37.84|              52.0|      696.0|         191.0|     345.0|     174.0|       2.6736|          191300.0|            3.0|\n",
      "|  -122.26|   37.85|              52.0|     2643.0|         626.0|    1212.0|     620.0|       1.9167|          159200.0|            3.0|\n",
      "|  -122.26|   37.85|              50.0|     1120.0|         283.0|     697.0|     264.0|        2.125|          140000.0|            3.0|\n",
      "|  -122.27|   37.85|              52.0|     1966.0|         347.0|     793.0|     331.0|        2.775|          152500.0|            3.0|\n",
      "|  -122.27|   37.85|              52.0|     1228.0|         293.0|     648.0|     303.0|       2.1202|          155500.0|            3.0|\n",
      "|  -122.26|   37.84|              50.0|     2239.0|         455.0|     990.0|     419.0|       1.9911|          158700.0|            3.0|\n",
      "|  -122.27|   37.84|              52.0|     1503.0|         298.0|     690.0|     275.0|       2.6033|          162900.0|            3.0|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"ocean_proximity\", outputCol=\"ocean_proximity_index\")\n",
    "indexed_df = indexer.fit(df).transform(df)\n",
    "\n",
    "df = indexed_df.drop(\"ocean_proximity\").withColumnRenamed(\"ocean_proximity_index\", \"ocean_proximity\")\n",
    "\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n7pyo-A1t4AS",
    "outputId": "4abcf8e0-3102-4f27-fe3e-45c9785a43b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|summary|          longitude|          latitude|housing_median_age|       total_rooms|    total_bedrooms|        population|        households|     median_income|median_house_value|   ocean_proximity|\n",
      "+-------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "|  count|              20433|             20433|             20433|             20433|             20433|             20433|             20433|             20433|             20433|             20433|\n",
      "|   mean|-119.57068859198068| 35.63322125972706|28.633093525179856|2636.5042333480155| 537.8705525375618|1424.9469485635982|499.43346547251997|3.8711616013312273|206864.41315519012|0.9094112465129937|\n",
      "| stddev|  2.003577890751096|2.1363476663779872|12.591805202182835| 2185.269566977601|421.38507007403115|1133.2084897449597| 382.2992258828481| 1.899291249306247|115435.66709858322|1.0045735326216698|\n",
      "|    min|            -124.35|             32.54|               1.0|               2.0|               1.0|               3.0|               1.0|            0.4999|           14999.0|               0.0|\n",
      "|    max|            -114.31|             41.95|              52.0|           39320.0|            6445.0|           35682.0|            6082.0|           15.0001|          500001.0|               4.0|\n",
      "+-------+-------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gJI1FlahugEy",
    "outputId": "48120dba-8af6-4f2d-8e67-9483efec1ff5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|longitude|latitude|housing_median_age|total_rooms|total_bedrooms|population|households|median_income|median_house_value|ocean_proximity|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "|  -122.23|   37.88|              41.0|      880.0|         129.0|     322.0|     126.0|       8.3252|          452600.0|            3.0|\n",
      "|  -122.22|   37.86|              21.0|     7099.0|        1106.0|    2401.0|    1138.0|       8.3014|          358500.0|            3.0|\n",
      "|  -122.24|   37.85|              52.0|     1467.0|         190.0|     496.0|     177.0|       7.2574|          352100.0|            3.0|\n",
      "|  -122.25|   37.85|              52.0|     1274.0|         235.0|     558.0|     219.0|       5.6431|          341300.0|            3.0|\n",
      "|  -122.25|   37.85|              52.0|     1627.0|         280.0|     565.0|     259.0|       3.8462|          342200.0|            3.0|\n",
      "|  -122.25|   37.85|              52.0|      919.0|         213.0|     413.0|     193.0|       4.0368|          269700.0|            3.0|\n",
      "|  -122.25|   37.84|              52.0|     2535.0|         489.0|    1094.0|     514.0|       3.6591|          299200.0|            3.0|\n",
      "|  -122.25|   37.84|              52.0|     3104.0|         687.0|    1157.0|     647.0|         3.12|          241400.0|            3.0|\n",
      "|  -122.26|   37.84|              42.0|     2555.0|         665.0|    1206.0|     595.0|       2.0804|          226700.0|            3.0|\n",
      "|  -122.25|   37.84|              52.0|     3549.0|         707.0|    1551.0|     714.0|       3.6912|          261100.0|            3.0|\n",
      "|  -122.26|   37.85|              52.0|     2202.0|         434.0|     910.0|     402.0|       3.2031|          281500.0|            3.0|\n",
      "|  -122.26|   37.85|              52.0|     3503.0|         752.0|    1504.0|     734.0|       3.2705|          241800.0|            3.0|\n",
      "|  -122.26|   37.85|              52.0|     2491.0|         474.0|    1098.0|     468.0|        3.075|          213500.0|            3.0|\n",
      "|  -122.26|   37.84|              52.0|      696.0|         191.0|     345.0|     174.0|       2.6736|          191300.0|            3.0|\n",
      "|  -122.26|   37.85|              52.0|     2643.0|         626.0|    1212.0|     620.0|       1.9167|          159200.0|            3.0|\n",
      "|  -122.26|   37.85|              50.0|     1120.0|         283.0|     697.0|     264.0|        2.125|          140000.0|            3.0|\n",
      "|  -122.27|   37.85|              52.0|     1966.0|         347.0|     793.0|     331.0|        2.775|          152500.0|            3.0|\n",
      "|  -122.27|   37.85|              52.0|     1228.0|         293.0|     648.0|     303.0|       2.1202|          155500.0|            3.0|\n",
      "|  -122.26|   37.84|              50.0|     2239.0|         455.0|     990.0|     419.0|       1.9911|          158700.0|            3.0|\n",
      "|  -122.27|   37.84|              52.0|     1503.0|         298.0|     690.0|     275.0|       2.6033|          162900.0|            3.0|\n",
      "+---------+--------+------------------+-----------+--------------+----------+----------+-------------+------------------+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9fdqtyyBt7hm"
   },
   "source": [
    "# Lineer Regresyon Modelinin kurulması"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zASLOV0mJGxv"
   },
   "source": [
    "##  VectorAssembler kullanarak özniteliklerin birleştirilmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "aQlb41MXvn-K"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "feature_columns = ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income','ocean_proximity']\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "data = assembler.transform(df).select(\"features\", \"median_house_value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XQyqHenmJLmD"
   },
   "source": [
    "## Veri kümesinin train ve test kümelerine bölünmesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "fFU_fDUWvtsm"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = data.randomSplit([0.8, 0.2], seed=1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OFJYmyPAJPFx"
   },
   "source": [
    "## Lineer Regresyon modelinin oluşturulması ve eğitimin yapılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "OhM0QS8JvyQi"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"median_house_value\")\n",
    "lr_model = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yo4B__XyKUTw"
   },
   "source": [
    "# R2 Skorunun Hesaplanması\n",
    "Lineer Regresyon modeli kullanılarak yapılan tahminlerin R2 skorunu hesaplar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tGZkMs7Mv3G7",
    "outputId": "483246c9-38ba-40f2-8e9f-873c8524bec0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.6416399219959245\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "predictions = lr_model.transform(test_data)\n",
    "evaluator = RegressionEvaluator(labelCol=\"median_house_value\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "40wMpia0u1OQ"
   },
   "source": [
    "# Özelliklerin scale edilmesi\n",
    "Veri setindeki özellikleri ölçeklemek iin standart scaler kullanılması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VXXgigoMu5qZ",
    "outputId": "fe5f53ca-ed8a-4089-c4d6-7ec5339ed7f9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|median_house_value|     scaled_features|\n",
      "+------------------+--------------------+\n",
      "|          452600.0|[-61.005863841998...|\n",
      "|          358500.0|[-61.000872770752...|\n",
      "|          352100.0|[-61.010854913244...|\n",
      "|          341300.0|[-61.015845984490...|\n",
      "|          342200.0|[-61.015845984490...|\n",
      "|          269700.0|[-61.015845984490...|\n",
      "|          299200.0|[-61.015845984490...|\n",
      "|          241400.0|[-61.015845984490...|\n",
      "|          226700.0|[-61.020837055737...|\n",
      "|          261100.0|[-61.015845984490...|\n",
      "|          281500.0|[-61.020837055737...|\n",
      "|          241800.0|[-61.020837055737...|\n",
      "|          213500.0|[-61.020837055737...|\n",
      "|          191300.0|[-61.020837055737...|\n",
      "|          159200.0|[-61.020837055737...|\n",
      "|          140000.0|[-61.020837055737...|\n",
      "|          152500.0|[-61.025828126983...|\n",
      "|          155500.0|[-61.025828126983...|\n",
      "|          158700.0|[-61.020837055737...|\n",
      "|          162900.0|[-61.025828126983...|\n",
      "+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "feature_cols = ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income','ocean_proximity']\n",
    "assembler = VectorAssembler(inputCols=feature_cols, outputCol=\"features\")\n",
    "df_vectorized = assembler.transform(df)\n",
    "\n",
    "scaler = StandardScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "\n",
    "scaler_model = scaler.fit(df_vectorized)\n",
    "\n",
    "scaled_df = scaler_model.transform(df_vectorized)\n",
    "\n",
    "scaled_df = scaled_df.select('median_house_value', 'scaled_features')\n",
    "\n",
    "scaled_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AbAfu6lZfpEL"
   },
   "source": [
    "# Scale edilmiş veri ile lineer regresyon modeli kurulması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "elm-KYM-whRV"
   },
   "outputs": [],
   "source": [
    "train_df, test_df = scaled_df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "klTVEAl6wsym"
   },
   "outputs": [],
   "source": [
    "lr = LinearRegression(featuresCol='scaled_features', labelCol='median_house_value')\n",
    "lr_model = lr.fit(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TXimC581w-MW",
    "outputId": "055d3f90-52d1-488e-8d41-ecb63ab43f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.6203821929804811\n"
     ]
    }
   ],
   "source": [
    "predictions = lr_model.transform(test_df)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol='median_house_value', predictionCol='prediction', metricName='r2')\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fS9taxTCt5u4"
   },
   "source": [
    "# Min-Max Scaler işleminin yapılması ve Lineer Regresyon modelinin kurulması"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "r-reJqCaw7qA"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import MinMaxScaler\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "feature_columns = ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income','ocean_proximity']\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "data = assembler.transform(df)\n",
    "\n",
    "scaler = MinMaxScaler(inputCol=\"features\", outputCol=\"scaled_features\")\n",
    "\n",
    "scaler_model = scaler.fit(data)\n",
    "\n",
    "scaled_data = scaler_model.transform(data)\n",
    "\n",
    "scaled_data = scaled_data.select('median_house_value', 'scaled_features')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fueiDnPga-uE",
    "outputId": "5ef4a25d-56d3-4ef9-8d3e-dd23fe737626"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+\n",
      "|median_house_value|     scaled_features|\n",
      "+------------------+--------------------+\n",
      "|          452600.0|[0.21115537848605...|\n",
      "|          358500.0|[0.21215139442231...|\n",
      "|          352100.0|[0.21015936254980...|\n",
      "|          341300.0|[0.20916334661354...|\n",
      "|          342200.0|[0.20916334661354...|\n",
      "|          269700.0|[0.20916334661354...|\n",
      "|          299200.0|[0.20916334661354...|\n",
      "|          241400.0|[0.20916334661354...|\n",
      "|          226700.0|[0.20816733067728...|\n",
      "|          261100.0|[0.20916334661354...|\n",
      "|          281500.0|[0.20816733067728...|\n",
      "|          241800.0|[0.20816733067728...|\n",
      "|          213500.0|[0.20816733067728...|\n",
      "|          191300.0|[0.20816733067728...|\n",
      "|          159200.0|[0.20816733067728...|\n",
      "|          140000.0|[0.20816733067728...|\n",
      "|          152500.0|[0.20717131474103...|\n",
      "|          155500.0|[0.20717131474103...|\n",
      "|          158700.0|[0.20816733067728...|\n",
      "|          162900.0|[0.20717131474103...|\n",
      "+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scaled_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "iCwDjYgTc-xI"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit\n",
    "train_data, test_data = scaled_data.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6C2Wva5sbAoj",
    "outputId": "eeb6168a-4c0d-4bba-ce01-f989b3464299"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score: 0.62038219297657\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "lr = LinearRegression(featuresCol='scaled_features', labelCol='median_house_value')\n",
    "\n",
    "lr_model = lr.fit(train_data)\n",
    "\n",
    "predictions = lr_model.transform(test_data)\n",
    "\n",
    "evaluator = RegressionEvaluator(labelCol='median_house_value', predictionCol='prediction', metricName='r2')\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "print(\"R2 Score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "y7SSPkothGo8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
